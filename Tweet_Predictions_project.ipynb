{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YPzPcPUiQ6jE","executionInfo":{"status":"ok","timestamp":1716619311126,"user_tz":-330,"elapsed":4733,"user":{"displayName":"sparsh sehgal","userId":"07315566695706608481"}}},"outputs":[],"source":["import pandas as pd\n","import re\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"oYhHF6J0R8Dm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90B6EpkBQ6jG"},"source":["Load the test data on which the predictions will be made using our best model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaRYlDjgQ6jI"},"outputs":[],"source":["congress_test = pd.read_csv('/content/drive/MyDrive/Data/Data/congress_test.csv')\n","bjp_test = pd.read_csv('/content/drive/MyDrive/Data/Data/bjp_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSwxhpiGQ6jJ"},"outputs":[],"source":["congress_test =congress_test[:2000]\n","bjp_test = bjp_test[0:2000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukpqHKLEQ6jK"},"outputs":[],"source":["congress_test[0:5]"]},{"cell_type":"markdown","metadata":{"id":"adFb9ts8Q6jL"},"source":["Preprocessing the test tweets in the same manner that we had done for the training data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k93T9kzUQ6jL"},"outputs":[],"source":["def tweet_to_words( raw_review ):\n","    # Remove non-letters\n","    letters_only = re.sub(\"[^a-zA-Z]\", \" \", str(raw_review))\n","    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', str(letters_only)) # remove URLs\n","    tweet = re.sub('RT', ' ', str(tweet))\n","\n","    #Convert to lower case, split into individual words\n","    tweet = letters_only.lower().split()\n","\n","\n","\n","    return( \" \".join(tweet))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvzAvImlQ6jM"},"outputs":[],"source":["# Get the number of Tweets based on the dataframe column size\n","num_tweets = 2000\n","\n","# Initialize an empty list to hold the clean reviews\n","\n","\n","# Loop over each tweet; create an index i that goes from 0 to the length\n","# of the tweet list\n","def clean_test(dataframe):\n","    clean_train_tweets = []\n","    for i in range( 0, num_tweets ):\n","        # Call function for each one, and add the result to the list of\n","        clean_train_tweets.append( tweet_to_words(dataframe[i]))\n","    return clean_train_tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tY_qurSPQ6jN"},"outputs":[],"source":["congress_inputs = clean_test(congress_test['clean_text'])\n","bjp_inputs = clean_test(bjp_test['clean_text'])"]},{"cell_type":"markdown","metadata":{"id":"x2MzGQUXQ6jO"},"source":["Tokenize the text data. The length of the vector is kept 2000. Because this was the same lenght that was using for the Bidirectional LSTM which was our best model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kFP0yJYQ6jP"},"outputs":[],"source":["def tokenze_data(data_inputs):\n","        tokenizer = Tokenizer(nb_words=2000)\n","        tokenizer.fit_on_texts(data_inputs)\n","        sequences = tokenizer.texts_to_sequences(data_inputs)\n","\n","        word_index = tokenizer.word_index\n","        print('Found %s unique tokens.' % len(word_index))\n","        max_len = 200\n","        data = pad_sequences(sequences, max_len)\n","        print('Shape of data tensor:', data.shape)\n","        indices = np.arange(data.shape[0])\n","        np.random.shuffle(indices)\n","        data = data[indices]\n","        return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Qm0IfBVQ6jQ"},"outputs":[],"source":["congress_inputs = np.array([\"Your\", \"congress\", \"input\", \"text\"])\n","bjp_inputs = np.array([\"Your\", \"bjp\", \"input\", \"text\"])\n","\n","congress_inputs = [str(text) for text in congress_inputs]\n","bjp_inputs = [str(text) for text in bjp_inputs]\n","\n","congress_inputs = tokenze_data(congress_inputs)\n","bjp_inputs = tokenze_data(bjp_inputs)\n"]},{"cell_type":"markdown","metadata":{"id":"gxLCVR24Q6jR"},"source":["**LOAD THE BEST MODEL (BIDIRECTIONAL LSTM)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTt8csmEQ6jS"},"outputs":[],"source":["from keras.models import model_from_json\n","# load json and create model\n","json_file = open(\"/content/drive/MyDrive/Data/SavedModels/Model_Bidir_LSTM.h5\", 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"/content/drive/MyDrive/Data/SavedModels/Weights_bidir_LSTM.h5\")\n","print(\"Loaded model from disk\")"]},{"cell_type":"markdown","metadata":{"id":"7e-rf0z9Q6jS"},"source":["**SENTIMENT PREDICTION USING THE MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNjVSOJUQ6jT"},"outputs":[],"source":["congress_prediction = loaded_model.predict(congress_inputs)\n","bjp_prediction = loaded_model.predict(bjp_inputs)"]},{"cell_type":"markdown","metadata":{"id":"br8KftRtQ6jT"},"source":["If the probabilty of the outcome is greater than 0.5 for any class then the sentiment belongs to that particular class. Since we are concerned with only the count of positive sentiments. We will check the second column variables for our inference."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XCcT3F_Q6jU"},"outputs":[],"source":["congress_pred = (congress_prediction>0.5)\n","bjp_pred = (bjp_prediction>0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"si4VAABoQ6jU"},"outputs":[],"source":["def get_predictions(party_pred):\n","    x = 0\n","    for i in party_pred:\n","        if(i[1]==True):\n","            x+=1\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67KYijjKQ6jU"},"outputs":[],"source":["congress_numbers = get_predictions(congress_pred)\n","bjp_numbers = get_predictions(bjp_pred)\n","print(\"Congress Positive Tweets:\",congress_numbers)\n","print(\"BJP Positive Tweets:\",bjp_numbers)"]},{"cell_type":"markdown","metadata":{"id":"eNIpZ0MxQ6jV"},"source":["Just like the training data the majority of the tweets have a negative sentiment attached to them. After feeding 2000 tweets for both the Congress and BJP. The model predicted that BJP has 660 positive tweets while Congress has 416 positive tweets.<br><br> This indicated that the contest this year would be close and the chances of BJP winning on Majority like the 2015 elections are less. This has been corraborated by the poor perfomace of the BJP in the recent state elections where the lost power in three Major Hindi speaking states Rajasthan, Madhya Pradesh and Chattishgarh. <br><br> The challanges faced in this project were the limited data availablity and that Twitter as a platform is only accessable to the elite urban population and I is difficult to make any absolute prediction on a phenomenon like the Indian Election. The Coming month will tell how things unfold for both the parties.  "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[{"file_id":"https://github.com/Satwik2602/Sentiment-Analysis-Indian-Elections/blob/main/Tweet_Predictions.ipynb","timestamp":1715710404925}]}},"nbformat":4,"nbformat_minor":0}